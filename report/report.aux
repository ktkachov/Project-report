\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{4}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}The domain}{4}{section.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}The Airfoil program}{5}{section.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}FPGAs, streaming and acceleration}{5}{section.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Visualisation of a reduced version of the Airfoil mesh \relax }}{6}{figure.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:airfoil_mesh}{{1.1}{6}{Visualisation of a reduced version of the Airfoil mesh \label {fig:airfoil_mesh}\relax \relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces A simple dataflow graph that implements the function $y(x) = x^2 + x$. The adder and the multiplication nodes are fully pipelined, enabling a throughput of one result per cycle, thus providing us with the intuition for accelerating floating point calculations \relax }}{7}{figure.caption.4}}
\newlabel{fig:graph_simple}{{1.2}{7}{A simple dataflow graph that implements the function $y(x) = x^2 + x$. The adder and the multiplication nodes are fully pipelined, enabling a throughput of one result per cycle, thus providing us with the intuition for accelerating floating point calculations \label {fig:graph_simple}\relax \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Contributions}{7}{section.1.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{9}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Unstructured meshes and their representation}{9}{section.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces An example mesh and its representation using indirection arrays. The cell numbers are shown inside the quadrilaterals formed by the nodes (circles) and edges (edges connecting the nodes). Together with the indirection map, we also store an integer $dim \in \mathbb  {N}$ which specifies the dimension of the mapping. Thus, the data associated with element $i$ are stored in the range $[i*dim$, ... , $i*(dim+1)-1]$ of the relevant indirection map (in the example: the nodes associated with edge 3 are stored at indices $3*2=6$ and $3*2+1=7$). Note: in the edge-to-cell map $-1$ represents a boundary cell that may be handled in a special way by a computational kernel. \relax }}{10}{figure.caption.5}}
\newlabel{fig:mesh_small_example}{{2.1}{10}{An example mesh and its representation using indirection arrays. The cell numbers are shown inside the quadrilaterals formed by the nodes (circles) and edges (edges connecting the nodes). Together with the indirection map, we also store an integer $dim \in \mathbb {N}$ which specifies the dimension of the mapping. Thus, the data associated with element $i$ are stored in the range $[i*dim$, ... , $i*(dim+1)-1]$ of the relevant indirection map (in the example: the nodes associated with edge 3 are stored at indices $3*2=6$ and $3*2+1=7$). Note: in the edge-to-cell map $-1$ represents a boundary cell that may be handled in a special way by a computational kernel. \label {fig:mesh_small_example}\relax \relax }{figure.caption.5}{}}
\citation{OP2_presentation}
\citation{OP2_presentation}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces An example mesh with coordinate data associated with each node ($(x,y)$ from $node\_id\nobreakspace  {}(x,y)$). The coordinate data will be represented as an array of floating point numbers $x = \{0.0,0.0, 2.78,5.0, 3.0,1.0, 3.0,6.7, 7.5,3.14, 9.0,7.7\}$. Again we also record the dimension of the data (in this case $dim=2$) in order to access the data set associated with each element. In this example, the coordinate data for node 4 is stored at indices $4*2=8$ and $4*2+1=9$ of the array $x$. \relax }}{11}{figure.caption.6}}
\newlabel{fig:data_set_ex}{{2.2}{11}{An example mesh with coordinate data associated with each node ($(x,y)$ from $node\_id~(x,y)$). The coordinate data will be represented as an array of floating point numbers $x = \{0.0,0.0, 2.78,5.0, 3.0,1.0, 3.0,6.7, 7.5,3.14, 9.0,7.7\}$. Again we also record the dimension of the data (in this case $dim=2$) in order to access the data set associated with each element. In this example, the coordinate data for node 4 is stored at indices $4*2=8$ and $4*2+1=9$ of the array $x$. \label {fig:data_set_ex}\relax \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Airfoil}{11}{section.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces An example mesh, showing data dependencies between edges that affect cell data. \relax }}{12}{figure.caption.7}}
\newlabel{fig:mesh_coloured}{{2.3}{12}{An example mesh, showing data dependencies between edges that affect cell data. \label {fig:mesh_coloured}\relax \relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Computational kernels and data sets}{13}{subsection.2.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Table showing the data sets and their types. In the actual implementation, we may choose to represent real numbers ($\mathbb  {R}$) as standard or double precision floating point numbers or as fixed point numbers (discussed later). Elements of dimension larger than one will be represented as arrays. The physical meaning of these sets is not important, however Airfoil is generally intereseted in computing a steady-state solution for the q data set.\relax }}{14}{table.caption.8}}
\newlabel{tab:Airfoil_datasets}{{2.1}{14}{Table showing the data sets and their types. In the actual implementation, we may choose to represent real numbers ($\mathbb {R}$) as standard or double precision floating point numbers or as fixed point numbers (discussed later). Elements of dimension larger than one will be represented as arrays. The physical meaning of these sets is not important, however Airfoil is generally intereseted in computing a steady-state solution for the q data set.\relax \relax }{table.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Table showing the kernels defined in airfoil and their data requirements.\relax }}{14}{table.caption.9}}
\newlabel{tab:Airfoil_kernels}{{2.2}{14}{Table showing the kernels defined in airfoil and their data requirements.\relax \relax }{table.caption.9}{}}
\@writefile{lol}{\contentsline {listing}{\numberline {1}{\ignorespaces  Definition of the res\_calc kernel with reals represented as single precision floating point numbers. Note the type signature. The kernel requires the element of the dataset x associated with each of the two nodes of the edge we are currently processing and the q, adt and res elements of the two cells associted with the current edge. Note that the res set is updated by incrementing ($+=$), introducing dependencies between parallel applications of the kernel to different edges. The important part of this definition are the data requirements of the kernel and not the exact meaning of the arithmetic operations. The variables $gm1$ and $eps$ are global constants that do not need to be passed in explicitly. \relax }}{15}{listing.1}}
\newlabel{lst:ResCalcKernelC}{{1}{15}{ Definition of the res\_calc kernel with reals represented as single precision floating point numbers. Note the type signature. The kernel requires the element of the dataset x associated with each of the two nodes of the edge we are currently processing and the q, adt and res elements of the two cells associted with the current edge. Note that the res set is updated by incrementing ($+=$), introducing dependencies between parallel applications of the kernel to different edges. The important part of this definition are the data requirements of the kernel and not the exact meaning of the arithmetic operations. The variables $gm1$ and $eps$ are global constants that do not need to be passed in explicitly.\label {lst:ResCalcKernelC} \relax \relax }{listing.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Indirection maps}{16}{subsection.2.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Diagram showing the maps between the mesh elements The dimension of the map is shown in parentheses next to the name. Thus the map \emph  {edge} relating edges to nodes with dimension 2 means that for each edge, there are two nodes associated with it. \relax }}{16}{figure.caption.10}}
\newlabel{fig:Airfoil_maps}{{2.4}{16}{Diagram showing the maps between the mesh elements The dimension of the map is shown in parentheses next to the name. Thus the map \emph {edge} relating edges to nodes with dimension 2 means that for each edge, there are two nodes associated with it. \label {fig:Airfoil_maps}\relax \relax }{figure.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Table showing the time spent in each kernel during a run of a single-threaded sequential version of Airfoil on a current CPU. The total run time is 115.6 seconds.\relax }}{17}{table.caption.11}}
\newlabel{tab:Airfoil_timesCPU}{{2.3}{17}{Table showing the time spent in each kernel during a run of a single-threaded sequential version of Airfoil on a current CPU. The total run time is 115.6 seconds.\relax \relax }{table.caption.11}{}}
\@writefile{lol}{\contentsline {listing}{\numberline {2}{\ignorespaces  The iteration structure of Airfoil.  \relax }}{18}{listing.2}}
\newlabel{lst:AirfoilIteration}{{2}{18}{ The iteration structure of Airfoil. \label {lst:AirfoilIteration} \relax \relax }{listing.2}{}}
\citation{Virtex6Spec}
\citation{MaxCompiler_whitepaper}
\citation{MaxCompiler_whitepaper}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Hardware platform, Maxeler toolchain and the streaming model of computation}{19}{section.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces A diagram of the Maxeler toolchain. The data-flow graphs of the computational kernels are defined using a Java API. A manager connects multiple kernels together and handles the streaming to and from the kernels of data. These are combined by MaxCompiler and compiled into a .max file that can then be linked to a host C/C++ or Fortran application using standard tools (gcc, ld etc). \relax }}{19}{figure.caption.12}}
\newlabel{fig:max_toolchain}{{2.5}{19}{A diagram of the Maxeler toolchain. The data-flow graphs of the computational kernels are defined using a Java API. A manager connects multiple kernels together and handles the streaming to and from the kernels of data. These are combined by MaxCompiler and compiled into a .max file that can then be linked to a host C/C++ or Fortran application using standard tools (gcc, ld etc). \label {fig:max_toolchain}\relax \relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}MaxCompiler example}{20}{subsection.2.3.1}}
\@writefile{lol}{\contentsline {listing}{\numberline {3}{\ignorespaces  A MaxCompiler definition of a kernel that computes a moving 3-point average with boundary conditions. Note that the arithmetic operators as well as the ternary if operator have been overloaded for HWVar objects that represent the value of a hardware stream.  \relax }}{20}{listing.3}}
\newlabel{lst:MaxCompilerMovAvg}{{3}{20}{ A MaxCompiler definition of a kernel that computes a moving 3-point average with boundary conditions. Note that the arithmetic operators as well as the ternary if operator have been overloaded for HWVar objects that represent the value of a hardware stream. \label {lst:MaxCompilerMovAvg} \relax \relax }{listing.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces The dataflow graph resulting from the code in Listing\nobreakspace  {}\ref  {lst:MaxCompilerMovAvg}. Note: the $stream.offset(x,-1)$ and $stream.offset(x,+1)$ expressions are shown here using the rhombuses with $+1$ and $-1$, evaluating the value of $x$ one cycle in the 'future' and one cycle in the past respectively. The other nodes have the obvious meanings.\relax }}{22}{figure.caption.13}}
\newlabel{fig:MovAvgGraph}{{2.6}{22}{The dataflow graph resulting from the code in Listing~\ref {lst:MaxCompilerMovAvg}. Note: the $stream.offset(x,-1)$ and $stream.offset(x,+1)$ expressions are shown here using the rhombuses with $+1$ and $-1$, evaluating the value of $x$ one cycle in the 'future' and one cycle in the past respectively. The other nodes have the obvious meanings.\relax \relax }{figure.caption.13}{}}
\@writefile{lol}{\contentsline {listing}{\numberline {4}{\ignorespaces  Manager specification for a MovingAverageKernel that streams the input data "x" from the host and streams the output data "y" to the host. The $<==$ operator means connect the right hand side stream to the left hand side stream. The above code instantiates the MovingAverageKernel, creates a stream called "x" from the host and connects it to the input stream "x" in the kernel. Then it creates a stream to the host called "y" and connects to it the output stream "y" from the kernel.  \relax }}{23}{listing.4}}
\newlabel{lst:MaxCompilerMovAvgManager}{{4}{23}{ Manager specification for a MovingAverageKernel that streams the input data "x" from the host and streams the output data "y" to the host. The $<==$ operator means connect the right hand side stream to the left hand side stream. The above code instantiates the MovingAverageKernel, creates a stream called "x" from the host and connects it to the input stream "x" in the kernel. Then it creates a stream to the host called "y" and connects to it the output stream "y" from the kernel. \label {lst:MaxCompilerMovAvgManager} \relax \relax }{listing.4}{}}
\@writefile{lol}{\contentsline {listing}{\numberline {5}{\ignorespaces  A sample host code using the MaxCompilerRT API for the C language.  \relax }}{25}{listing.5}}
\newlabel{lst:MovAvgHostCode}{{5}{25}{ A sample host code using the MaxCompilerRT API for the C language. \label {lst:MovAvgHostCode} \relax \relax }{listing.5}{}}
\citation{Virtex6Spec}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Hardware}{26}{subsection.2.3.2}}
\citation{METISPaper}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Diagram of the hardware parts of a MAX card, showing the relationships between the DRAM, PCIe, the host and the FPGA.\relax }}{27}{figure.caption.14}}
\newlabel{fig:maxHW}{{2.7}{27}{Diagram of the hardware parts of a MAX card, showing the relationships between the DRAM, PCIe, the host and the FPGA.\relax \relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Mesh partitioning and halos}{27}{subsection.2.3.3}}
\citation{IEEEFP}
\citation{IEEEFP}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces A mesh partitioned into 4 partitions, shown in green. The halo regions are shown in purple. Nodes, cells and edges belonging to the halo region can be accessed by another partition.\relax }}{28}{figure.caption.15}}
\newlabel{fig:partition}{{2.8}{28}{A mesh partitioned into 4 partitions, shown in green. The halo regions are shown in purple. Nodes, cells and edges belonging to the halo region can be accessed by another partition.\relax \relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Floating point vs fixed point arithmetic}{28}{subsection.2.3.4}}
\citation{OP2_presentation}
\citation{OP2_Cluster}
\citation{OP2_presentation}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces The representation of an IEEE-754 single precision floating point number. It has 8 bits for the exponent and 24 bits for the mantissa. However, one bit of the mantissa is used to represent the sign, and is therefore unavailable to the rest of the mantissa.\relax }}{29}{figure.caption.16}}
\newlabel{fig:FPSP}{{2.9}{29}{The representation of an IEEE-754 single precision floating point number. It has 8 bits for the exponent and 24 bits for the mantissa. However, one bit of the mantissa is used to represent the sign, and is therefore unavailable to the rest of the mantissa.\relax \relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Previous work}{29}{section.2.4}}
\citation{UnstructuredMeshCCM}
\citation{MemoryHierarchy}
\citation{SpanishFPGAAirfoil}
\citation{SpanishFPGAAirfoil2}
\citation{SpanishFPGAAirfoil}
\citation{ElectromagneticsFPGA}
\citation{MeshIntensityROSE}
\citation{MeshCache}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Design and Modelling}{33}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}DRAM and mesh storage}{33}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Result accumulation and storage}{34}{section.3.2}}
\citation{GhostCellPaper}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Simplified architecture diagram of the accelerator showing the block RAMs storing the node and cell data, the arithmetic pipeline, the result block RAMs and the accumulator. The connectivity information is used to address the block RAMs.\relax }}{35}{figure.caption.17}}
\newlabel{fig:Architecture1st}{{3.1}{35}{Simplified architecture diagram of the accelerator showing the block RAMs storing the node and cell data, the arithmetic pipeline, the result block RAMs and the accumulator. The connectivity information is used to address the block RAMs.\relax \relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Halo exchange mechanism}{35}{section.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Architecture diagram of the accelerator with the PCIe halo exchange mechanism. The RAM selectors will select which RAM to read the cell and node data from based on the edge information. They are also used to pick the RAM to write the results back to. The dashed lines represent addresses that are used to access the RAMs and to determine which RAMs to access.\relax }}{37}{figure.caption.18}}
\newlabel{fig:ArchitecturePCIe}{{3.2}{37}{Architecture diagram of the accelerator with the PCIe halo exchange mechanism. The RAM selectors will select which RAM to read the cell and node data from based on the edge information. They are also used to pick the RAM to write the results back to. The dashed lines represent addresses that are used to access the RAMs and to determine which RAMs to access.\relax \relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Two-level partitioning}{38}{section.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Partitioning of a macro-partition into two micro-partitions. This introduces a new intra-partition halo region, shown here in crimson.\relax }}{39}{figure.caption.19}}
\newlabel{fig:upartition}{{3.3}{39}{Partitioning of a macro-partition into two micro-partitions. This introduces a new intra-partition halo region, shown here in crimson.\relax \relax }{figure.caption.19}{}}
\citation{Pipeline}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Architecture diagram showing the addition of a state machine (node SM) that controls the I/O and the processing. The red wires represent the boolean enable signals. The halo and normal RAMs as well as the RAM selectors are shown in merged blocks for brevity.\relax }}{40}{figure.caption.20}}
\newlabel{fig:ArchitectureSM}{{3.4}{40}{Architecture diagram showing the addition of a state machine (node SM) that controls the I/O and the processing. The red wires represent the boolean enable signals. The halo and normal RAMs as well as the RAM selectors are shown in merged blocks for brevity.\relax \relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Diagram showing the overlapping of execution and I/O thanks to the two-level partitioning scheme. Note that both micro-partitions need the intra-partition halo (IPH) in order to be processed, so the IPH can only be written out together with the second micro-partition after both micro-partitions ($\mu $partitions) have been processed. The red boxes represent the progress of a single (macro)partition through the accelerator phases.\relax }}{41}{figure.caption.21}}
\newlabel{fig:partPipeline}{{3.5}{41}{Diagram showing the overlapping of execution and I/O thanks to the two-level partitioning scheme. Note that both micro-partitions need the intra-partition halo (IPH) in order to be processed, so the IPH can only be written out together with the second micro-partition after both micro-partitions ($\mu $partitions) have been processed. The red boxes represent the progress of a single (macro)partition through the accelerator phases.\relax \relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}The case for a custom streaming pipeline}{42}{section.3.5}}
\citation{SpanishFPGAAirfoil}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Diagram showing the computation of the function $r=x^2 + y - \sqrt  {z}$\relax }}{45}{figure.caption.22}}
\newlabel{fig:StreamVsCPU}{{3.6}{45}{Diagram showing the computation of the function $r=x^2 + y - \sqrt {z}$\relax \relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Performance Model}{45}{section.3.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Phase 1}{47}{subsection.3.6.1}}
\citation{TeslaM2050}
\citation{OpenCL}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Phase 2}{48}{subsection.3.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}Phase 3}{48}{subsection.3.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.4}Design space exploration}{49}{subsection.3.6.4}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Table showing the time spent in each kernel during a run of a hardware accelerated version of Airfoil on a Tesla M2050 GPU. The total run time is 9.67 seconds.\relax }}{49}{table.caption.23}}
\newlabel{tab:Airfoil_timesCPU}{{3.1}{49}{Table showing the time spent in each kernel during a run of a hardware accelerated version of Airfoil on a Tesla M2050 GPU. The total run time is 9.67 seconds.\relax \relax }{table.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{Number of arithmetic pipelines $n_p$}{49}{section*.24}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Plot of estimated execution time for 2000 iterations of res\_calc against the number of arithmetic pipelines in the architecture. The clock frequency is set to 240MHz. \relax }}{50}{figure.caption.25}}
\newlabel{fig:Pipelines}{{3.7}{50}{Plot of estimated execution time for 2000 iterations of res\_calc against the number of arithmetic pipelines in the architecture. The clock frequency is set to 240MHz. \label {fig:Pipelines}\relax \relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {subsubsection}{Clock frequency $f$}{51}{section*.26}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Plot of estimated execution time for 2000 iterations of res\_calc against the clock frequency of the FPGA using one arithmetic pipeline. \relax }}{51}{figure.caption.27}}
\newlabel{fig:frequencies}{{3.8}{51}{Plot of estimated execution time for 2000 iterations of res\_calc against the clock frequency of the FPGA using one arithmetic pipeline. \label {fig:frequencies}\relax \relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsubsection}{Clock frequency $f$ and arithmetic pipelines $n_p$}{51}{section*.28}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Plot of estimated execution time for 2000 iterations of res\_calc against the clock frequency of the FPGA for various numbers of arithmetic pipelines. \relax }}{52}{figure.caption.29}}
\newlabel{fig:frequencies_pipelines}{{3.9}{52}{Plot of estimated execution time for 2000 iterations of res\_calc against the clock frequency of the FPGA for various numbers of arithmetic pipelines. \label {fig:frequencies_pipelines}\relax \relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Plot of estimated execution time for 2000 iterations of res\_calc against the clock frequency of the FPGA for various numbers of arithmetic pipelines in a 3-dimensional plot. \relax }}{52}{figure.caption.30}}
\newlabel{fig:frequencies_pipelines3D}{{3.10}{52}{Plot of estimated execution time for 2000 iterations of res\_calc against the clock frequency of the FPGA for various numbers of arithmetic pipelines in a 3-dimensional plot. \label {fig:frequencies_pipelines3D}\relax \relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsubsection}{Partition size $C_{pp}$}{53}{section*.31}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Plot of estimated execution time for 2000 iterations of res\_calc against the number of cells per partition. Note that the horizontal axis is on a log-2 scale. The design has 8 pipelines and runs at 240MHz.\relax }}{53}{figure.caption.32}}
\newlabel{fig:partition_sizes}{{3.11}{53}{Plot of estimated execution time for 2000 iterations of res\_calc against the number of cells per partition. Note that the horizontal axis is on a log-2 scale. The design has 8 pipelines and runs at 240MHz.\relax \relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Plot of estimated DRAM to PCIe transfer time ratio ($\genfrac  {}{}{}0{t_{DRAM}}{t_{PCIe}}$) against the number of cells per partition. Note that the horizontal axis is on a log-2 scale.The design has 8 pipelines and runs at 240MHz.\relax }}{54}{figure.caption.33}}
\newlabel{fig:partition_ratios}{{3.12}{54}{Plot of estimated DRAM to PCIe transfer time ratio ($\dfrac {t_{DRAM}}{t_{PCIe}}$) against the number of cells per partition. Note that the horizontal axis is on a log-2 scale.The design has 8 pipelines and runs at 240MHz.\relax \relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Implementation}{55}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Mesh partitioning}{55}{section.4.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Edge scheduling}{56}{section.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Architecture diagram of the accumulation part of the accelerator design showing the conflicting values of $res$ being computed in the accumulator pipeline. The conflicting values for address $\alpha _{0}$ are shown in red.\relax }}{57}{figure.caption.34}}
\newlabel{fig:edge_dependency}{{4.1}{57}{Architecture diagram of the accumulation part of the accelerator design showing the conflicting values of $res$ being computed in the accumulator pipeline. The conflicting values for address $\alpha _{0}$ are shown in red.\relax \relax }{figure.caption.34}{}}
\@writefile{prog}{\contentsline {program}{\numberline {1}{\ignorespaces Pseudocode that validates an edge schedule $sch$ of $n$ edges with window width $l$.\relax }}{57}{program.1}}
\newlabel{alg:valid_schedule}{{1}{57}{Pseudocode that validates an edge schedule $sch$ of $n$ edges with window width $l$.\relax \relax }{program.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces An example partitioning of a micro-partition into 11 edge partitions (left) and the adjacency graph generated from that partitioning (right).\relax }}{58}{figure.caption.35}}
\newlabel{fig:parts_graph}{{4.2}{58}{An example partitioning of a micro-partition into 11 edge partitions (left) and the adjacency graph generated from that partitioning (right).\relax \relax }{figure.caption.35}{}}
\@writefile{prog}{\contentsline {program}{\numberline {2}{\ignorespaces Pseudocode that validates a node schedule $sch$ of an adjacency graph $g$ with $n$ elements for a window width of $l$.\relax }}{59}{program.2}}
\newlabel{alg:valid_schedule_graph}{{2}{59}{Pseudocode that validates a node schedule $sch$ of an adjacency graph $g$ with $n$ elements for a window width of $l$.\relax \relax }{program.2}{}}
\@writefile{prog}{\contentsline {program}{\numberline {3}{\ignorespaces Pseudocode that computes a schedule for the nodes in a graph $g$ with window width $l$.\relax }}{60}{program.3}}
\newlabel{alg:schedule_algorithm}{{3}{60}{Pseudocode that computes a schedule for the nodes in a graph $g$ with window width $l$.\relax \relax }{program.3}{}}
\@writefile{prog}{\contentsline {program}{\numberline {4}{\ignorespaces Pseudocode that checks whether inserting node $n$ at position $c$ into the schedule $arr$ will produce a valid partial schedule for window width $l$ of the nodes in graph $g$.\relax }}{61}{program.4}}
\newlabel{alg:schedule_validPos}{{4}{61}{Pseudocode that checks whether inserting node $n$ at position $c$ into the schedule $arr$ will produce a valid partial schedule for window width $l$ of the nodes in graph $g$.\relax \relax }{program.4}{}}
\bibcite{OP2_presentation}{1}
\bibcite{OP2_Cluster}{2}
\bibcite{Virtex6Spec}{3}
\bibcite{MaxCompiler_whitepaper}{4}
\bibcite{METISPaper}{5}
\bibcite{IEEEFP}{6}
\bibcite{GhostCellPaper}{7}
\bibcite{UnstructuredMeshCCM}{8}
\bibcite{MemoryHierarchy}{9}
\bibcite{SpanishFPGAAirfoil}{10}
\bibcite{SpanishFPGAAirfoil2}{11}
\bibcite{ElectromagneticsFPGA}{12}
\bibcite{MeshIntensityROSE}{13}
\bibcite{MeshCache}{14}
\bibcite{floatFPGA}{15}
\bibcite{Pipeline}{16}
\bibcite{OpenCL}{17}
\bibcite{TeslaM2050}{18}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Appendix}{65}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Airfoil Kernel definitions in C}{65}{section.5.1}}
